#Environment file verififed by CoPilot
# ===============================
# OPENAI CONFIGURATION
# ===============================

# API key for Vocareum OpenAI
OPENAI_KEY="voc-2009866425126677464339669333e56cd9164.50366416"
OPENAI_API_KEY="voc-2009866425126677464339669333e56cd9164.50366416"

# Base URL for all OpenAI/Vocareum requests
OPENAI_BASE_URL="https://openai.vocareum.com/v1"

client1 = OpenAI(base_url=OPENAI_BASE_URL, api_key=OPENAI_KEY)


# MODEL SETTINGS
##################################################
# Default chat model used by llm_client.py
OPENAI_CHAT_MODEL="gpt-3.5-turbo"

# Default embedding model used in embedding.py
OPENAI_EMBED_MODEL="text-embedding-3-small"

# RAG CONFIGURATION 
###############################################

# Directory for ChromaDB persistence
CHROMA_DIR="chroma_db"

# Chroma collection name
CHROMA_COLLECTION="nasa_missions"

# CHUNKING SETTINGS
###############################################

# Token chunk size for document splitting
CHUNK_TOKENS=550

# Token overlap between chunks
CHUNK_OVERLAP_TOKENS=80

# RETRIEVAL PARAMETERS
###############################################

# How many document chunks to retrieve
TOP_K=6

# LLM RESPONSE SETTINGS
###############################################

# Temperature for response variance
TEMPERATURE=0.2

# Maximum number of assistant output tokens
MAX_OUTPUT_TOKENS=700

# Maximum retained conversation turns
MAX_HISTORY_TURNS=8